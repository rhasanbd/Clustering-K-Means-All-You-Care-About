{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means: Optimization Techniques\n",
    "\n",
    "In this notebook, we discuss techniques for optimizing the performance of K-Means. More specifically, we address the following two questions?\n",
    "\n",
    "\n",
    "- Question 1: How to avoid converging to a suboptimal solution?\n",
    "- Question 2: How to accelerate the speed of convergence?\n",
    "\n",
    "\n",
    "These questions are resolved by the following two variants of the K-Means algorithm, respectively.\n",
    "\n",
    "- K-Means++: Uses a smarter initialization step to ensure that the selected centroids are distant from one another.\n",
    "- Elkan's K-Means: Accelerates the speed by avoiding many unnecessary distance calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Dataset\n",
    "\n",
    "We will use Scikit-Learn's \"make_blobs\" function to generate isotropic Gaussian blobs for clustering. \n",
    "\n",
    "This function provides greater control regarding the centers and standard deviations of each cluster.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blob Centers and Standard Deviations\n",
    "\n",
    "First define 5 blob centers by providing their coordinates.\n",
    "\n",
    "Then, define the standard deviations of each blob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_centers = np.array(\n",
    "    [[ 0.2,  2.3],\n",
    "     [-1.5 ,  2.3],\n",
    "     [-2.8,  1.8],\n",
    "     [-2.8,  2.8],\n",
    "     [-2.8,  1.3]])\n",
    "\n",
    "blob_std = np.array([0.4, 0.3, 0.1, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "\n",
    "Note that \"X\" represents the generated 2D samples.\n",
    "\n",
    "And \"y\" represents the integer labels for cluster membership of each sample.\n",
    "\n",
    "Since we generate five clusters, the indices would be: 0, 1, 2, 3, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=2000, centers=blob_centers,\n",
    "                  cluster_std=blob_std, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: How to avoid converging to a suboptimal solution?\n",
    "\n",
    "\n",
    "## Solution: K-Means++\n",
    "\n",
    "K-Means++ is an important improvement to the K-Means algorithm that aims to solve the following problem:\n",
    "\n",
    "        How to avoid converging to a suboptimal solution?\n",
    "\n",
    "It was proposed in a 2006 paper by David Arthur and Sergei Vassilvitskii. \n",
    "\n",
    "Unlike K-Means that selects the centroids randomly, K-Means++ employs a smarter initialization step. It ensures that the selected centroids are distant from one another which resolves the suboptimal convergence issue.\n",
    "\n",
    "This initialization step requires some additional computation. But this drastically reduces the number of times the algorithm needs to be run to find the optimal solution.\n",
    "\n",
    "The K-Means++ initialization algorithm is as follows:\n",
    "\n",
    "- Take one centroid $c_1$, chosen uniformly at random from the dataset.\n",
    "- Take a new center $c_i$, choosing an instance $\\mathbf{x}_i$ with probability: $D(\\mathbf{x}_i)^2$ / $\\sum\\limits_{j=1}^{m}{D(\\mathbf{x}_j)}^2$ where $D(\\mathbf{x}_i)$ is the distance between the instance $\\mathbf{x}_i$ and the closest centroid that was already chosen. This probability distribution ensures that instances that are further away from already chosen centroids are much more likely be selected as centroids.\n",
    "- Repeat the previous step until all $k$ centroids have been chosen.\n",
    "\n",
    "The rest of the K-Means++ algorithm is just regular K-Means. \n",
    "\n",
    "With this initialization, the K-Means algorithm is much less likely to converge to a suboptimal solution, so it is possible to reduce n_init considerably. \n",
    "\n",
    "Most of the time, this largely compensates for the additional complexity of the initialization process.\n",
    "\n",
    "To set the initialization to K-Means++, simply set init=\"k-means++\" (this the default setting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inertia:  211.5985372581684\n"
     ]
    }
   ],
   "source": [
    "good_init = np.array([[-3, 3], [-3, 2], [-3, 1], [-1, 2], [0, 2]])\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, init=good_init, n_init=1, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "print(\"Inertia: \", kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Question 2: How to accelerate the speed of convergence?\n",
    "\n",
    "## Solution: Elkan's K-Means\n",
    "\n",
    "Elkan's variant of K-Means accelerates the algorithm by avoiding many unnecessary distance calculations.\n",
    "\n",
    "This is achieved by exploiting the triangle inequality (given three points A, B and C, the distance AC is always such that AC ≤ AB + BC) and by keeping track of lower and upper bounds for distances between instances and centroids.\n",
    "\n",
    "To use Elkan's variant of K-Means, just set algorithm=\"elkan\". \n",
    "\n",
    "Note that it does not support sparse data, so by default, Scikit-Learn uses \"elkan\" for dense data, and \"full\" (the regular K-Means algorithm) for sparse data.\n",
    "\n",
    "\n",
    "To evaluate the performance of the Elkan's K-Means algorithm we will use the \"timeit\" function.\n",
    "\n",
    "### %timeit\n",
    "\n",
    "To fit a model multiple time and computing its mean & std, we will use the %timeit function\n",
    "\n",
    "%timeit is a magic function, which can be used to time a particular piece of code (A single execution statement, or a single method).\n",
    "\n",
    "When called as a program from the command line, the following form is used:\n",
    "\n",
    "[-n N] [-r N] [statement ...]\n",
    "\n",
    "-n N, --number=N\n",
    "how many times to execute ‘statement’\n",
    "\n",
    "-r N, --repeat=N\n",
    "how many times to repeat the timer (default 3)\n",
    "\n",
    "-s S, --setup=S\n",
    "statement to be executed once initially (default pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Required by Elkan's K-Means:\n",
      "\n",
      "89.2 ms ± 3.2 ms per loop (mean ± std. dev. of 7 runs, 50 loops each)\n"
     ]
    }
   ],
   "source": [
    "print(\"Time Required by Elkan's K-Means:\\n\")\n",
    "%timeit -n 50 KMeans(algorithm=\"elkan\").fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Required by Vanilla K-Means:\n",
      "\n",
      "113 ms ± 1.69 ms per loop (mean ± std. dev. of 7 runs, 50 loops each)\n"
     ]
    }
   ],
   "source": [
    "print(\"Time Required by Vanilla K-Means:\\n\")\n",
    "%timeit -n 50 KMeans(algorithm=\"full\").fit(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
